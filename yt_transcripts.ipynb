{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You Tube transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Crawler, Analyzer, aggregate_analysis_files, VideoInfo\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for YT channels of Florida cities and towns\n",
    "\n",
    "So we go over the list of all cities in Florida and search YouTube for \"city of XYZ Florida\" and \"town of XYZ Florida\". This is what `Crawler` class does. See docstring in Crawler for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [00:33,  7.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quota exceeded. Stopping crawling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crawler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each json response we now ask ChatGPT to determine is the channel official or not, this creates csv file in analysis folder, and updates in status.csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "437it [00:15, 29.02it/s]\n"
     ]
    }
   ],
   "source": [
    "analyzer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now aggregate the results in a single csv file, storing only yes results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError\n",
    "from utils import ANALYSIS_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading analysis/AT00007244.csv. Skipping it.\n"
     ]
    }
   ],
   "source": [
    "aggregate_analysis_files(crawler, 'aggregated_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract info from one video with video id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example YouTube video ID\n",
    "# https://www.youtube.com/watch?v=AH4XSLg6rvw&t=588s\n",
    "video_id = \"5AIBek1jhfE\"  # ID is what comes after 'v=' in URL: https://www.youtube.com/watch?v=5AIBek1jhfE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoInfo(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# Initialize the YouTube Data API client\n",
    "youtube = build('youtube', 'v3', developerKey=yt_api_key)\n",
    "\n",
    "\n",
    "def get_channel_id(youtube, channel_username):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"id\",\n",
    "        forUsername=channel_username\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response['items'][0]['id'] if response['items'] else None\n",
    "\n",
    "\n",
    "def get_live_streams_from_channel(channel_id):\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token,\n",
    "            order=\"date\",\n",
    "            type=\"video\",\n",
    "            eventType=\"live\"  # This filters for live streams only\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_info = {\n",
    "                \"video_id\": item['id']['videoId'],\n",
    "                \"title\": item['snippet']['title'],\n",
    "                \"description\": item['snippet']['description'],\n",
    "                \"published_at\": item['snippet']['publishedAt']\n",
    "            }\n",
    "            videos.append(video_info)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example channel username (can also be channel ID if known)\n",
    "channel_username = \"townoffortmyersbeachfl33931\"\n",
    "\n",
    "# Get the channel ID\n",
    "channel_id = get_channel_id(youtube, channel_username)\n",
    "if not channel_id:\n",
    "    print(f\"Channel not found for username: {channel_username}\")\n",
    "else:\n",
    "    # Get the live streams from the channel\n",
    "    live_streams = get_live_streams_from_channel(channel_id)\n",
    "    \n",
    "    # Print the live streams\n",
    "    for video in live_streams:\n",
    "        print(f\"Video ID: {video['video_id']}\")\n",
    "        print(f\"Title: {video['title']}\")\n",
    "        print(f\"Description: {video['description']}\")\n",
    "        print(f\"Published At: {video['published_at']}\")\n",
    "        print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
