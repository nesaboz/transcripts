{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You Tube transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ChannelCrawler, ChannelAnalyzer, aggregate_analysis_files, VideoInfo\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for YT channels of Florida cities and towns\n",
    "\n",
    "So we go over the list of all cities in Florida and search YouTube for \"city of XYZ Florida\" and \"town of XYZ Florida\". This is what `Crawler` class does. See docstring in Crawler for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = ChannelCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [00:33,  7.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quota exceeded. Stopping crawling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crawler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each json response we now ask ChatGPT to determine is the channel official or not, this creates csv file in analysis folder, and updates in status.csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = ChannelAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "437it [00:15, 29.02it/s]\n"
     ]
    }
   ],
   "source": [
    "analyzer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now aggregate the results in a single csv file, storing only yes results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading analysis/AT00007244.csv. Skipping it.\n"
     ]
    }
   ],
   "source": [
    "aggregate_analysis_files(crawler, 'aggregated_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all live videos from one channel\n",
    "\n",
    "We now feed in channel id and get all the live videos from that channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_channel_id, get_live_streams_from_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m channel_username \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtownoffortmyersbeachfl33931\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the channel ID\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m channel_id \u001b[38;5;241m=\u001b[39m \u001b[43mget_channel_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_username\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m channel_id\n",
      "File \u001b[0;32m~/Projects/transcripts/utils.py:320\u001b[0m, in \u001b[0;36mget_channel_id\u001b[0;34m(channel_username)\u001b[0m\n\u001b[1;32m    315\u001b[0m request \u001b[38;5;241m=\u001b[39m youtube\u001b[38;5;241m.\u001b[39mchannels()\u001b[38;5;241m.\u001b[39mlist(\n\u001b[1;32m    316\u001b[0m     part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m     forUsername\u001b[38;5;241m=\u001b[39mchannel_username\n\u001b[1;32m    318\u001b[0m )\n\u001b[1;32m    319\u001b[0m response \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "# Example channel username (can also be channel ID if known)\n",
    "channel_username = \"townoffortmyersbeachfl33931\"\n",
    "\n",
    "# Get the channel ID\n",
    "channel_id = get_channel_id(channel_username)\n",
    "\n",
    "channel_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_live_streams_from_channel('UCBTiCuq7bdOfOjqAnHY0zbA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/channel/UCBTiCuq7bdOfOjqAnHY0zbA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not channel_id:\n",
    "    print(f\"Channel not found for username: {channel_username}\")\n",
    "else:\n",
    "    # Get the live streams from the channel\n",
    "    live_streams = get_live_streams_from_channel(channel_id)\n",
    "    \n",
    "    # Print the live streams\n",
    "    for video in live_streams:\n",
    "        print(f\"Video ID: {video['video_id']}\")\n",
    "        print(f\"Title: {video['title']}\")\n",
    "        print(f\"Description: {video['description']}\")\n",
    "        print(f\"Published At: {video['published_at']}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract info from one video with video id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example YouTube video ID\n",
    "# https://www.youtube.com/watch?v=AH4XSLg6rvw&t=588s\n",
    "video_id = \"5AIBek1jhfE\"  # ID is what comes after 'v=' in URL: https://www.youtube.com/watch?v=5AIBek1jhfE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoInfo(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
